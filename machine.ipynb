{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l1_l2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para criar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o modelo\n",
    "def criar_modelo(input_shape=4, regularization_rate=0.01):\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Input(shape=(input_shape,)))\n",
    "    \n",
    "    # Primeira camada oculta\n",
    "    modelo.add(Dense(units=5, activation='relu', \n",
    "                    kernel_regularizer=l1_l2(regularization_rate)))\n",
    "    modelo.add(BatchNormalization())\n",
    "    modelo.add(Dropout(0.2))\n",
    "    \n",
    "    # Segunda camada oculta\n",
    "    modelo.add(Dense(units=4, activation='relu',\n",
    "                    kernel_regularizer=l1_l2(regularization_rate)))\n",
    "    modelo.add(BatchNormalization())\n",
    "    modelo.add(Dropout(0.2))\n",
    "    \n",
    "    # Camada de saída\n",
    "    modelo.add(Dense(units=3, activation=\"softmax\"))\n",
    "    \n",
    "    modelo.compile(optimizer=\"adam\", \n",
    "                  loss=\"categorical_crossentropy\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebendo e tratando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = datasets.load_iris()\n",
    "previsores = base.data\n",
    "classe = base.target\n",
    "\n",
    "#Passando os dados da classe para one hot encoding\n",
    "classe_dummy = to_categorical(classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando e configurando o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do K-Fold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "historicos = []\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "#Loop principal do Fold\n",
    "for fold, (treino_idx, teste_idx) in enumerate(kfold.split(previsores), 1):\n",
    "# Separar dados de treino e teste\n",
    "    x_treinamento, x_teste = previsores[treino_idx], previsores[teste_idx]\n",
    "    y_treinamento, y_teste = classe_dummy[treino_idx], classe_dummy[teste_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar os dados do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "x_treinamento = scaler.fit_transform(x_treinamento)\n",
    "x_teste = scaler.transform(x_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação da estrutura da rede neural com classe Sequencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Criar e treinar o modelo\n",
    "modelo = criar_modelo()\n",
    "historico = modelo.fit(\n",
    "    x_treinamento, y_treinamento,\n",
    "        epochs=100,\n",
    "        validation_data=(x_teste, y_teste),\n",
    "        verbose=2,\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "previsoes = modelo.predict(x_teste)\n",
    "y_teste_matrix = [np.argmax(t) for t in y_teste]\n",
    "y_previsoes_matrix = [np.argmax(t) for t in previsoes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calcular métricas\n",
    "accuracy = accuracy_score(y_teste_matrix, y_previsoes_matrix)\n",
    "f1 = f1_score(y_teste_matrix, y_previsoes_matrix, average='weighted')\n",
    "    \n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "    \n",
    "    # Armazenar resultados\n",
    "historicos.append(historico.history)\n",
    "accuracies.append(accuracy)\n",
    "f1_scores.append(f1)\n",
    "\n",
    "# Plotar resultados\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Gráfico de accuracy durante treinamento do último fold\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(historicos[-1]['accuracy'], label='Treino')\n",
    "plt.plot(historicos[-1]['val_accuracy'], label='Validação')\n",
    "plt.title('Acurácia do Modelo (Último Fold)')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend()\n",
    "\n",
    "# Box plot das acurácias de todos os folds\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(accuracies)\n",
    "plt.title('Distribuição das Acurácias')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Folds')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir resultados finais\n",
    "print(\"\\nResultados Finais:\")\n",
    "print(f\"Média da Acurácia: {np.mean(accuracies):.4f} (±{np.std(accuracies):.4f})\")\n",
    "print(f\"Média do F1-Score: {np.mean(f1_scores):.4f} (±{np.std(f1_scores):.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar matriz de confusão com o último fold\n",
    "confusao = confusion_matrix(y_teste_matrix, y_previsoes_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusao, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=base.target_names,\n",
    "            yticklabels=base.target_names)\n",
    "plt.xlabel(\"Classe Predita\")\n",
    "plt.ylabel(\"Classe Real\")\n",
    "plt.title(\"Matriz de Confusão (Último Fold)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
